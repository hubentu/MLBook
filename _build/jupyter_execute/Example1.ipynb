{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11272e2f",
   "metadata": {},
   "source": [
    "## Example\n",
    "Let’s walk through a practical example of using machine learning to build a predictive model. We’ll follow a structured approach that covers the entire machine learning pipeline, including:\n",
    "\n",
    "1. **Problem Definition**\n",
    "2. **Data Exploration (EDA)**\n",
    "3. **Data Cleaning**\n",
    "4. **Feature Engineering**\n",
    "5. **Model Selection**\n",
    "6. **Model Evaluation**\n",
    "7. **Model Tuning**\n",
    "8. **Deployment and Monitoring**\n",
    "\n",
    "We'll use a fictitious problem to keep things straightforward and generalizable. Suppose we are working on predicting **whether a customer will churn** (i.e., stop using the service) based on customer data for a telecom company.\n",
    "\n",
    "---\n",
    "\n",
    "### **Problem Definition**\n",
    "**Objective:** Predict whether a customer will churn (yes/no) based on customer data such as demographics, usage patterns, and service history.\n",
    "\n",
    "**Data:** You are provided with a dataset containing customer features:\n",
    "- **CustomerID**: Unique identifier for each customer.\n",
    "- **Tenure**: How long the customer has been with the company.\n",
    "- **MonthlyCharges**: The amount billed to the customer monthly.\n",
    "- **TotalCharges**: The total amount billed.\n",
    "- **Contract**: The type of contract (e.g., month-to-month, one year).\n",
    "- **PaymentMethod**: How the customer pays (e.g., credit card, bank transfer).\n",
    "- **Churn**: The target variable (1 for churn, 0 for no churn).\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Data Exploration (EDA)**\n",
    "\n",
    "We begin by loading and exploring the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a2927be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customerID  Gender  SeniorCitizen Partner Dependents  Tenure PhoneService  \\\n",
      "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
      "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
      "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
      "3  7795-CFOCW    Male              0      No         No      45           No   \n",
      "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
      "\n",
      "  MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
      "0            No             DSL             No  ...               No   \n",
      "1            No             DSL            Yes  ...              Yes   \n",
      "2            No             DSL            Yes  ...               No   \n",
      "3            No             DSL            Yes  ...              Yes   \n",
      "4            No     Fiber optic             No  ...               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies  Contract PaperlessBilling  \\\n",
      "0          No          No              No   Monthly              Yes   \n",
      "1          No          No              No  One year               No   \n",
      "2          No          No              No   Monthly              Yes   \n",
      "3         Yes          No              No  One year               No   \n",
      "4          No          No              No   Monthly              Yes   \n",
      "\n",
      "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
      "0                     Manual          29.85         29.85    No  \n",
      "1                     Manual          56.95        1889.5    No  \n",
      "2                     Manual          53.85        108.15   Yes  \n",
      "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
      "4                     Manual          70.70        151.65   Yes  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('https://github.com/YBIFoundation/Dataset/raw/main/TelecomCustomerChurn.csv')\n",
    "\n",
    "# Display first few rows\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae54e342",
   "metadata": {},
   "source": [
    "**Initial Checks:**\n",
    "- **Summary statistics** of numerical features: mean, median, and distribution of each variable.\n",
    "  \n",
    "```python\n",
    "# Summary statistics\n",
    "print(data.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "```\n",
    "\n",
    "- **Class imbalance:** Check the distribution of the target variable (`Churn`). Imbalanced classes could affect model performance.\n",
    "  \n",
    "```python\n",
    "# Check class distribution\n",
    "print(data['Churn'].value_counts())\n",
    "sns.countplot(x='Churn', data=data)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Visualizing Correlations:**\n",
    "Visualize the correlation between numerical features (e.g., tenure, monthly charges) and churn to detect potential patterns.\n",
    "\n",
    "```python\n",
    "# Correlation matrix\n",
    "corr = data.corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Insights from EDA:\n",
    "- If the target variable `Churn` is imbalanced (e.g., 80% no churn, 20% churn), we might need to address this during model training.\n",
    "- Monthly charges and tenure could show strong correlation with churn, providing clues for feature importance.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Data Cleaning**\n",
    "\n",
    "We now handle missing data, incorrect formats, and other issues.\n",
    "\n",
    "```python\n",
    "# Handle missing values in 'TotalCharges'\n",
    "# 'TotalCharges' might have some empty strings that need to be converted to NaN and filled.\n",
    "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Fill missing values in 'TotalCharges' with the median\n",
    "data['TotalCharges'].fillna(data['TotalCharges'].median(), inplace=True)\n",
    "```\n",
    "\n",
    "**Categorical Variable Encoding:**\n",
    "For categorical features like `Contract` and `PaymentMethod`, convert them to numerical format using one-hot encoding or label encoding.\n",
    "\n",
    "```python\n",
    "# One-hot encode categorical variables\n",
    "data = pd.get_dummies(data, columns=['Contract', 'PaymentMethod'], drop_first=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Feature Engineering**\n",
    "\n",
    "Next, we generate new features and modify existing ones to improve the model’s ability to predict churn.\n",
    "\n",
    "1. **Customer Tenure Grouping:**\n",
    "   Customers with longer tenures might behave differently, so we can bucket the `Tenure` feature into categories.\n",
    "   \n",
    "```python\n",
    "# Create tenure groups\n",
    "bins = [0, 12, 24, 36, 48, 60, 72]\n",
    "labels = ['0-12', '12-24', '24-36', '36-48', '48-60', '60-72']\n",
    "data['TenureGroup'] = pd.cut(data['Tenure'], bins=bins, labels=labels)\n",
    "```\n",
    "\n",
    "2. **Interaction Features:**\n",
    "   Interaction between features like `MonthlyCharges` and `Contract` type might provide insight into churn behavior.\n",
    "   \n",
    "```python\n",
    "# Interaction term between MonthlyCharges and Contract type\n",
    "data['Charges_Contract'] = data['MonthlyCharges'] * data['Contract_One year']\n",
    "```\n",
    "\n",
    "3. **Log Transformation:**\n",
    "   If `TotalCharges` is highly skewed, applying a log transformation can make the distribution more normal and improve model performance.\n",
    "   \n",
    "```python\n",
    "import numpy as np\n",
    "data['Log_TotalCharges'] = np.log1p(data['TotalCharges'])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4: Model Selection**\n",
    "\n",
    "We now split the data into training and test sets and select candidate models to compare.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets\n",
    "X = data.drop(['Churn', 'CustomerID'], axis=1)  # Features\n",
    "y = data['Churn']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "**Model Choices:**\n",
    "We'll test multiple models, including:\n",
    "- **Logistic Regression** (baseline)\n",
    "- **Random Forest**\n",
    "- **Gradient Boosting (XGBoost or LightGBM)**\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize models\n",
    "log_reg = LogisticRegression()\n",
    "rf = RandomForestClassifier()\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# Fit models\n",
    "log_reg.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 5: Model Evaluation**\n",
    "\n",
    "Evaluate the performance of each model using relevant metrics.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "# Make predictions\n",
    "log_reg_pred = log_reg.predict(X_test)\n",
    "rf_pred = rf.predict(X_test)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_score(y_test, log_reg_pred)}\")\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test, rf_pred)}\")\n",
    "print(f\"XGBoost Accuracy: {accuracy_score(y_test, xgb_pred)}\")\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_test, xgb_pred))\n",
    "\n",
    "# ROC-AUC Score\n",
    "print(f\"XGBoost ROC-AUC: {roc_auc_score(y_test, xgb_pred)}\")\n",
    "```\n",
    "\n",
    "For imbalanced datasets, focus on metrics like precision, recall, F1 score, and ROC-AUC rather than accuracy alone.\n",
    "\n",
    "**Confusion Matrix:**\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Confusion matrix for XGBoost\n",
    "cm = confusion_matrix(y_test, xgb_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 6: Model Tuning**\n",
    "\n",
    "Once we have a good model, we perform hyperparameter tuning using techniques like **Grid Search** or **Random Search**.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='roc_auc', verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(grid_search.best_params_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 7: Handling Imbalanced Data**\n",
    "\n",
    "Since churn is likely an imbalanced problem, we can address this by:\n",
    "\n",
    "1. **Oversampling the minority class** (using SMOTE):\n",
    "   \n",
    "```python\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)\n",
    "```\n",
    "\n",
    "2. **Class weighting** (in RandomForestClassifier or XGBoost):\n",
    "   \n",
    "```python\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "xgb = XGBClassifier(scale_pos_weight=(sum(y_train == 0) / sum(y_train == 1)))  # For imbalanced datasets\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 8: Model Deployment and Monitoring**\n",
    "\n",
    "Once the model is trained and tested, we package it for deployment. Using a framework like **Flask** or **FastAPI**, we can serve the model predictions through an API.\n",
    "\n",
    "```python\n",
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "\n",
    "# Load the trained model\n",
    "with open('xgb_model.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    prediction = model.predict([data['features']])\n",
    "    return jsonify({'prediction': int(prediction[0])})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n",
    "```\n",
    "\n",
    "Finally, we monitor the model in production using key performance indicators (KPIs) such as accuracy drift or changes in the distribution of incoming data, ensuring the model continues to perform well.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "\n",
    "\n",
    "This pipeline outlines a complete approach for building a machine learning model, from data exploration to deployment. It demonstrates a real-world application that includes model tuning, handling imbalanced data, and ensuring deployment-ready code. This structure is typical of how a machine learning engineer would approach building a model end-to-end in a professional setting."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "source_map": [
   10,
   47,
   57
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}